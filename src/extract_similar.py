#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä» code_train.txt / tgt_train.txt ä¸­ï¼ŒåŸºäº TF-IDF + æœ€è¿‘é‚»æ£€ç´¢ï¼Œ
ä¸ºæ¯æ¡æ ·æœ¬æ‰¾åˆ°æœ€ç›¸ä¼¼ï¼ˆä½†éè‡ªèº«ï¼‰çš„æºç /æ³¨é‡Šå¯¹ï¼Œç”Ÿæˆ similar.code å’Œ similar.comment
è¾“å‡ºæ ¼å¼ä¸åŸå§‹é¡¹ç›®ä¸€è‡´ï¼šæ¯è¡Œä¸€ä¸ª '<BEG> â€¦ <END>'ã€‚
"""
import os
import sys
from tqdm import tqdm
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import NearestNeighbors

def load_lines(path):
    print(f"ğŸ” æ­£åœ¨è¯»å–æ–‡ä»¶: {path}")
    with open(path, 'r', encoding='utf-8') as f:
        lines = [l.strip() for l in f]
    print(f"âœ… è¯»å–å®Œæˆï¼Œå…± {len(lines)} è¡Œ")
    return lines

def wrap_be(l):
    return f"<BEG> {l} <END>"

def main(code_in, comment_in, out_sim_code, out_sim_comment, k=2):
    # 1. è¯»å…¥
    codes = load_lines(code_in)
    comments = load_lines(comment_in)
    assert len(codes) == len(comments), "âŒ é”™è¯¯ï¼šæºç å’Œæ³¨é‡Šè¡Œæ•°éœ€ä¸€è‡´"
    n_samples = len(codes)
    print(f"ğŸ“¦ æ ·æœ¬æ€»æ•°: {n_samples}")

    # 2. TF-IDF å»ºç«‹å‘é‡ç©ºé—´
    print("ğŸ› ï¸  æ„å»º TF-IDF å‘é‡... è¯·ç¨å€™")
    tfidf = TfidfVectorizer(token_pattern=r"(?u)\b\w+\b", lowercase=False)
    X = tfidf.fit_transform(codes)
    print(f"âœ… TF-IDF æ„å»ºå®Œæˆï¼Œå‘é‡å½¢çŠ¶: {X.shape}")
    print(f"è¯è¡¨å¤§å°: {len(tfidf.vocabulary_)}")

    # 3. æœ€è¿‘é‚»æ£€ç´¢ï¼ˆæ’é™¤è‡ªèº«ï¼Œå–ç¬¬ 2 æœ€è¿‘é‚»ï¼‰
    print("ğŸ” å¼€å§‹æœ€è¿‘é‚»æ£€ç´¢...")
    nbrs = NearestNeighbors(n_neighbors=k, metric='cosine', algorithm='auto').fit(X)
    distances, indices = nbrs.kneighbors(X, return_distance=True)
    # æ‰“å°å‰ 5 ä¸ªæ ·æœ¬çš„è¿‘é‚»ä¿¡æ¯
    print("å‰ 5 ä¸ªæ ·æœ¬çš„è¿‘é‚» (æ’é™¤è‡ªèº«åç¬¬1è¿‘é‚»):")
    for i in range(min(5, n_samples)):
        # ç¬¬ä¸€è¿‘é‚»æ˜¯è‡ªèº«ï¼Œå–ç¬¬äºŒ
        sim = indices[i][1] if indices[i][0] == i else indices[i][0]
        print(f"  æ ·æœ¬ {i} -> è¿‘é‚» {sim}ï¼Œè·ç¦» {distances[i][1]:.4f}")

    # 4. è¾“å‡º similar.code / similar.comment
    print(f"âœï¸ å†™å‡ºæ–‡ä»¶: {out_sim_code} å’Œ {out_sim_comment}")
    with open(out_sim_code, 'w', encoding='utf-8') as f_code, \
         open(out_sim_comment, 'w', encoding='utf-8') as f_com:
        for i, nbr_idxs in enumerate(tqdm(indices, desc="å†™å‡ºç›¸ä¼¼å¯¹", ncols=80)):
            sim_idx = nbr_idxs[1] if nbr_idxs[0] == i else nbr_idxs[0]
            f_code.write(wrap_be(codes[sim_idx]) + "\n")
            f_com.write(wrap_be(comments[sim_idx]) + "\n")
            if (i + 1) % 10000 == 0:
                print(f"  å·²å¤„ç† {i+1}/{n_samples} æ¡")

    print("ğŸ‰ å®Œæˆ similar.code å’Œ similar.comment çš„ç”Ÿæˆï¼")

if __name__ == "__main__":
    import argparse
    p = argparse.ArgumentParser(description="åŸºäº TF-IDF + è¿‘é‚»æ£€ç´¢æ„å»º similar.code/similar.comment")
    p.add_argument("-i_code",   required=True, help="è¾“å…¥ï¼šcode_train.txt")
    p.add_argument("-i_com",    required=True, help="è¾“å…¥ï¼štgt_train.txt")
    p.add_argument("-o_simc",   required=True, help="è¾“å‡ºï¼šsimilar.code")
    p.add_argument("-o_simcm",  required=True, help="è¾“å‡ºï¼šsimilar.comment")
    p.add_argument("-k",        type=int, default=2, help="è¿‘é‚»æ•°ï¼Œé»˜è®¤2ï¼ˆæ’é™¤è‡ªèº«åå–ç¬¬1è¿‘é‚»ï¼‰")
    args = p.parse_args()

    main(args.i_code, args.i_com, args.o_simc, args.o_simcm, k=args.k)
